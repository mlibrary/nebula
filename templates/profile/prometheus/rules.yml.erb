# Managed by puppet (nebula/profile/prometheus/rules.yml.erb)
groups:
- name: hardware
  rules:
  - alert: PrometheusNotRunning
    annotations:
      summary: 'Prometheus server {{$labels.hostname}} isn''t collecting metrics.'
    expr: 'absent(up{job="prometheus"})'
    for: 5m
    labels:
      severity: page
  - alert: PuppetBehind
    annotations:
      summary: 'Node {{$labels.host | reReplaceAll "\\..*" ""}} hasn''t recently synced with puppet.'
    expr: 'puppet_report{environment="production",host!="ht-web-preview.umdl.umich.edu"} < (time() - (30 * 60))'
    for: 30m
    labels:
      severity: ticket
  - alert: PuppetResourcesFailing
    annotations:
      summary: 'Node {{$labels.host | reReplaceAll "\\..*" ""}} has failing puppet resources.'
    expr: >
      sum without(name)(
        puppet_report_events{environment="production", name="Failure"}
      ) + sum without(name)(
        puppet_report_resources{environment="production", name="Failed"}
      ) > 0
    for: 2h
    labels:
      severity: ticket
  - alert: PuppetZeroResources
    annotations:
      summary: 'Node {{$labels.host | reReplaceAll "\\..*" ""}} has zero puppet resources.'
    expr: 'puppet_report_resources{environment="production", name="Total"} == 0'
    for: 2h
    labels:
      severity: ticket
  - alert: LinuxInstanceDown
    annotations:
      summary: 'Linux node {{$labels.hostname}} isn''t responding to Prometheus.'
    expr: 'up{job="node",hostname!="ht-web-preview"} == 0'
    for: 30m
    labels:
      severity: page
  - alert: WindowsInstanceDown
    annotations:
      summary: 'Windows node {{$labels.hostname}} isn''t responding to Prometheus.'
    expr: 'up{job="wmi"} == 0'
    for: 30m
    labels:
      severity: page
  - alert: DiskSlowlyFillingUp
    annotations:
      summary: 'Filesystem {{$labels.hostname}}:{{$labels.mountpoint}} will fill up in a few days.'
    expr: >
      predict_linear(
        node_filesystem_avail_bytes{mountpoint!="/aspace", device!~".*/aspace", fstype!="afs", fstype!="tmpfs", device!="rootfs"}[1d],
        4 * 60 * 60 * 24
      ) < 0
    for: 12h
    labels:
      severity: ticket
  - alert: DiskAboutToFillUp
    annotations:
      summary: 'Filesystem {{$labels.hostname}}:{{$labels.mountpoint}} is filling up fast.'
    expr: >
      predict_linear(
        node_filesystem_avail_bytes{mountpoint!="/aspace", device!~".*/aspace", fstype!="afs", fstype!="tmpfs", device!="rootfs"}[1h],
        4 * 60 * 60
      ) < 0
    for: 30m
    labels:
      severity: page
  - alert: DiskPressure
    annotations:
      summary: 'Filesystem {{$labels.hostname}}:{{$labels.mountpoint}} is more than 95% full.'
    expr: >
      (
        (
          avg_over_time(
            node_filesystem_size_bytes{mountpoint!="/usr", mountpoint!="/aspace", fstype!="afs", fstype!="nfs", fstype!="tmpfs", fstype!="cifs", device!="rootfs"}[1m]
          ) - avg_over_time(
            node_filesystem_avail_bytes[1m]
          )
        ) / avg_over_time(
          node_filesystem_size_bytes[1m]
        )
      ) > 0.95
    for: 30m
    labels:
      severity: ticket
  - alert: DiskFull
    annotations:
      summary: 'Filesystem {{$labels.hostname}}:{{$labels.mountpoint}} is full.'
    expr: >
      (
        (
          avg_over_time(
            node_filesystem_size_bytes{mountpoint!="/usr", mountpoint!="/aspace", fstype!="afs", fstype!="nfs", fstype!="tmpfs", fstype!="cifs", device!="rootfs"}[1m]
          ) - avg_over_time(
            node_filesystem_avail_bytes[1m]
          )
        ) / avg_over_time(
          node_filesystem_size_bytes[1m]
        )
      ) > 0.99
    for: 5m
    labels:
      severity: page
  - alert: DiskRunningOutOfINodes
    annotations:
      summary: 'Filesystem {{$labels.hostname}}:{{$labels.mountpoint}} is running out of inodes.'
    expr: 'node_filesystem_files_free{fstype!="cifs",fstype!="vfat",fstype!="fuse.lxcfs",fstype!="rpc_pipefs"} < 10000'
    for: 30m
    labels:
      severity: page
  - alert: WindowsUpdateBehind
    annotations:
      summary: 'Node {{$labels.hostname}} has not updated in 40+ days.'
    expr: 'time() - windows_update > 40*24*3600'
    for: 1h
    labels:
      severity: ticket

  # We like to keep at least 3T free at all times for deep blue data,
  # but their ingest process requires double the capacity of any files
  # being ingested, so it is common for them to claim a lot of space
  # only temporarily. Hence the lengthy 1d alert threshold.
  - alert: DeepBlueDataProdStoragePressure
    annotations:
      summary: 'deepbluedata-prod ({{$labels.hostname}}:{{$labels.mountpoint}}) has less than 3T of free space'
    expr: 'node_filesystem_avail_bytes{device="deepbluedata-prod.value.storage.umich.edu:/deepbluedata-prod"} < 3 * 1024 * 1024 * 1024 * 1024'
    for: 1d
    labels:
      severity: ticket

  # This doesn't appear to grow fast, so an 100G threshold should give
  # plenty of time to address any problems.
  - alert: HTDevStoragePressure
    annotations:
      summary: 'htdev ({{$labels.hostname}}:{{$labels.mountpoint}}) has less than 100G of free space'
    expr: 'node_filesystem_avail_bytes{device=~"htdev.value.storage.umich.edu:/htdev.*"} < 100 * 1024 * 1024 * 1024'
    for: 1d
    labels:
      severity: ticket

  # These are legacy alerts that can be removed when RHEL5 is gone.
  - alert: DiskPressure
    expr: >
      (
        (
          avg_over_time(
            node_filesystem_size{mountpoint!="/usr", mountpoint!="/aspace", fstype!="afs", fstype!="nfs", fstype!="tmpfs", fstype!="cifs", device!="rootfs"}[1m]
          ) - avg_over_time(
            node_filesystem_avail[1m]
          )
        ) / avg_over_time(
          node_filesystem_size[1m]
        )
      ) > 0.95
    for: 30m
    labels:
      severity: ticket
    annotations:
      summary: 'Filesystem {{$labels.hostname}}:{{$labels.mountpoint}} is more than 95% full.'
  - alert: DiskFull
    expr: >
      (
        (
          avg_over_time(
            node_filesystem_size{mountpoint!="/usr", mountpoint!="/aspace", fstype!="afs", fstype!="nfs", fstype!="tmpfs", fstype!="cifs", device!="rootfs"}[1m]
          ) - avg_over_time(
            node_filesystem_avail[1m]
          )
        ) / avg_over_time(
          node_filesystem_size[1m]
        )
      ) > 0.99
    for: 5m
    labels:
      severity: page
    annotations:
      summary: 'Filesystem {{$labels.hostname}}:{{$labels.mountpoint}} is full.'
  - alert: DarkBlueFillingUp
    expr: >
      node_filesystem_avail_bytes{device="<%= @rules_variables['darkblue_device'] %>"} < (1 * 1024 * 1024 * 1024 * 1024)
    for: 10m
    labels:
      severity: ticket
    annotations:
      summary: 'Dark Blue repository storage, {{$labels.device}} is running low on available space.'
      description: '{{$labels.device}} has had less than 1TB of available space for more than 10 minutes.'
  - alert: DarkBlueFull
    expr: >
      node_filesystem_avail_bytes{device="<%= @rules_variables['darkblue_device'] %>"} < (100 * 1024 * 1024 * 1024)
    for: 5m
    labels:
      severity: page
    annotations:
      summary: 'Dark Blue repository storage, {{$labels.device}} is out of available space.'
      description: '{{$labels.device}} has had less than 100GB of available space for more than 5 minutes.'
  - alert: MysqlDown
    expr: >
      mysql_up == 0
    for: 5m
    labels:
      severity: page
    annotations:
      summary: 'MySQL is DOWN on {{$labels.hostname}}'
      description: 'MySQL is DOWN'
  - alert: MysqlSlaveSqlDown
    expr: >
      mysql_slave_status_slave_sql_running  == 0
    for: 5m
    labels:
      severity: page
    annotations:
      summary: 'MySQL Slave SQL is Not Running on {{$labels.hostname}}'
      description: 'MySQL Slave SQL is not Running'
  - alert: MysqlMaxPreparedStatment
    expr: >
      mysql_global_status_prepared_stmt_count / mysql_global_variables_max_prepared_stmt_count > 0.75
    for: 30m
    labels:
      severity: ticket
    annotations:
      summary: 'MySQL Prepared Statement Count is approaching MAX on {{$labels.hostname}}'
      description: 'MySQL Prepared Statement Count is approaching MAX'

  # These are aggregate rules for federated collection across our full
  # system. By putting them here, we essentially precompile them.
  - record: datacenter_role:network_transmit_bytes:rate5m
    expr: >
      sum without(device, hostname, instance)(
        rate(node_network_transmit_bytes_total[5m])
      )
  - record: datacenter_role:network_receive_bytes:rate5m
    expr: >
      sum without(device, hostname, instance)(
        rate(node_network_receive_bytes_total[5m])
      )
  - record: datacenter_role:node_cpu_seconds:max_not_idle_mean30s
    expr: >
      max without(hostname, instance)(
        avg without(cpu, mode)(
          1 - rate(node_cpu_seconds_total{mode="idle"}[30s])
        )
      )
  - record: datacenter_role:node_cpu_seconds:max_not_idle_mean2m
    expr: >
      max without(hostname, instance)(
        avg without(cpu)(
          sum without(mode)(
            rate(node_cpu_seconds_total{mode!="idle"}[2m])
          )
        )
      )
  - record: backend_datacenter:haproxy_server_up:count_servers_per_backend
    expr: >
      count without(server)(
        min without(hostname, instance, priority)(
          haproxy_server_up
        )
      )

  - record: backend_datacenter:haproxy_server_up:sum_servers_up_per_backend
    expr: >
      sum without(server)(
        min without(hostname, instance, priority)(
          haproxy_server_up
        )
      )
