<?xml version="1.0" encoding="UTF-8" ?>
<!-- $Id: solrconfig.xml,v 1.6 2017/10/10 21:00:26 tburtonw Exp tburtonw $ -->
<!--
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the "License"); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->

<!-- 
     For more details about configurations options that may appear in
     this file, see http://wiki.apache.org/solr/SolrConfigXml. 
-->
<config>
  <!-- In all configuration below, a prefix of "solr." for class names
       is an alias that causes solr to search appropriate packages,
       including org.apache.solr.(search|update|request|core|analysis)

       You may also specify a fully qualified Java classname if you
       have your own custom plugins.
    -->

  <!-- Controls what version of Lucene various components of Solr
       adhere to.  Generally, you want to use the latest version to
       get all bug fixes and improvements. It is highly recommended
       that you fully re-index after changing this setting as it can
       affect both how text is indexed and queried.
  -->
  <luceneMatchVersion>6.6.0</luceneMatchVersion>

  <!-- <lib/> directives can be used to instruct Solr to load any Jars
       identified and use them to resolve any "plugins" specified in
       your solrconfig.xml or schema.xml (ie: Analyzers, Request
       Handlers, etc...).

       All directories and paths are resolved relative to the
       instanceDir.

       Please note that <lib/> directives are processed in the order
       that they appear in your solrconfig.xml file, and are "stacked" 
       on top of each other when building a ClassLoader - so if you have 
       plugin jars with dependencies on other jars, the "lower level" 
       dependency jars should be loaded first.

       If a "./lib" directory exists in your instanceDir, all files
       found in it are included as if you had used the following
       syntax...
       
              <lib dir="./lib" />
    -->

  <!-- A 'dir' option by itself adds any files found in the directory 
       to the classpath, this is useful for including all jars in a
       directory.

       When a 'regex' is specified in addition to a 'dir', only the
       files in that directory which completely match the regex
       (anchored on both ends) will be included.

       If a 'dir' option (with or without a regex) is used and nothing
       is found that matches, a warning will be logged.

       The examples below can be used to load some solr-contribs along 
       with their external dependencies.
    -->
  <lib dir="${solr.install.dir:../../../..}/contrib/extraction/lib" regex=".*\.jar" />
  <lib dir="${solr.install.dir:../../../..}/dist/" regex="solr-cell-\d.*\.jar" />

  <lib dir="${solr.install.dir:../../../..}/contrib/clustering/lib/" regex=".*\.jar" />
  <lib dir="${solr.install.dir:../../../..}/dist/" regex="solr-clustering-\d.*\.jar" />

  <lib dir="${solr.install.dir:../../../..}/contrib/langid/lib/" regex=".*\.jar" />
  <lib dir="${solr.install.dir:../../../..}/dist/" regex="solr-langid-\d.*\.jar" />

  <lib dir="${solr.install.dir:../../../..}/contrib/ltr/lib/" regex=".*\.jar" />
  <lib dir="${solr.install.dir:../../../..}/dist/" regex="solr-ltr-\d.*\.jar" />

  <lib dir="${solr.install.dir:../../../..}/contrib/velocity/lib" regex=".*\.jar" />
  <lib dir="${solr.install.dir:../../../..}/dist/" regex="solr-velocity-\d.*\.jar" />

  <!-- an exact 'path' can be used instead of a 'dir' to specify a 
       specific jar file.  This will cause a serious error to be logged 
       if it can't be loaded.
    -->
  <!--
     <lib path="../a-jar-that-does-not-exist.jar" /> 
  -->

  <!-- tbw -->
  <schemaFactory class="ClassicIndexSchemaFactory"/>
  <!-- tbw copied below from ref guide p 649 -->
  <!-- An example of Solr's implicit default behavior if no
        no schemaFactory is explicitly defined.
  -->
  <!--
    <schemaFactory class="ManagedIndexSchemaFactory">
      <bool name="mutable">true</bool>
      <str name="managedSchemaResourceName">managed-schema</str>
    </schemaFactory>
   
  -->

  
  <!-- Data Directory

       Used to specify an alternate directory to hold all index data
       other than the default ./data under the Solr home.  If
       replication is in use, this should match the replication
       configuration.
    -->
  <dataDir>${solr.data.dir:}</dataDir>

  
<!-- tbw commented out default.  Since we index offline, we don't need  NRT.
Besides this has a 4MB default merge which is wrong for our nearly 1MB docs.
 Shawn suggested on the mailing list we use theMMapDirectoryFactory See this
http://lucene.472066.n3.nabble.com/When-not-to-use-NRTCachingDirectory-and-what-to-use-instead-tt4076978.html
 and email tbw sent of July 10
Try MMapDirectory for now.  If that doesn't work move to standard dir
-->

<!--
  <directoryFactory name="DirectoryFactory"
                    class="${solr.directoryFactory:solr.NRTCachingDirectoryFactory}"/>
-->

<!-- Docs suggest that maxChunkSize be set to 1 << 30 (1073741824) on 64-bit machines -->

  <directoryFactory name="DirectoryFactory"
                    class="${solr.directoryFactory:solr.MMapDirectoryFactory}"
		    maxChunkSize="1073741824"/>






  
  <!-- The CodecFactory for defining the format of the inverted index.
       The default implementation is SchemaCodecFactory, which is the official Lucene
       index format, but hooks into the schema to provide per-field customization of
       the postings lists and per-document values in the fieldType element
       (postingsFormat/docValuesFormat). Note that most of the alternative implementations
       are experimental, so if you choose to customize the index format, it's a good
       idea to convert back to the official format e.g. via IndexWriter.addIndexes(IndexReader)
       before upgrading to a newer version to avoid unnecessary reindexing.
       A "compressionMode" string element can be added to <codecFactory> to choose 
       between the existing compression modes in the default codec: "BEST_SPEED" (default)
       or "BEST_COMPRESSION".
  -->
  <codecFactory class="solr.SchemaCodecFactory"/>

  <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       Index Config - These settings control low-level behavior of indexing
       Most example settings here show the default value, but are commented
       out, to more easily see where customizations have been made.
       
       Note: This replaces <indexDefaults> and <mainIndex> from older versions
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
  <indexConfig>
    <useCompoundFile>false</useCompoundFile> 

    <!-- change this and parameters below so each shard merges at different rate-->
     <ramBufferSizeMB>960</ramBufferSizeMB> 
    
     <mergePolicyFactory class="org.apache.solr.index.TieredMergePolicyFactory">
       <int name="maxMergeAtOnce">30</int>
       <int name="segmentsPerTier">40</int>
       
       <double name="maxMergedSegmentMB">20000</double>-->
       <!-- don't know what to set this to to prevent any CFS-->
       <!--could try maxCFSSegmentSizeMB instead
	   WARNING  this might blow up try 128MB which should accomodate small segments See https://www.slideshare.net/sematext/solr-search-engine-optimize-is-not-bad-for-you -->
       <!--<double name="noCFSRatio">0.0</double>-->
       <int name="maxCFSSegmentSizeMB">128</int>
       
       
     </mergePolicyFactory>
     
     
	<!--tbw find email from Shawn where this was suggested-->
       <mergeScheduler class="org.apache.lucene.index.ConcurrentMergeScheduler">
         <int name="maxThreadCount">1</int>
         <int name="maxMergeCount">6</int> 
       </mergeScheduler>

 <!-- Switching back to 'single' to allow for the index and config to be shared via snap with the search solrs. - skorner -->
 <lockType>${solr.lock.type:single}</lockType>

<!-- we may need to update this to not keep even 1 need to check -->
    <deletionPolicy class="solr.SolrDeletionPolicy">
       <str name="maxCommitsToKeep">1</str> 
      <!-- The number of optimized commit points to be kept -->
      <str name="maxOptimizedCommitsToKeep">0</str> 
    </deletionPolicy>


    <!-- Maximum time to wait for a write lock (ms) for an IndexWriter. Default: 1000 -->
    <!-- <writeLockTimeout>1000</writeLockTimeout>  -->

    <infoStream>true</infoStream>
    <metrics>
      <!--major/minor determined by number of docs not size
	  currently each shard holds about 1 million docs, so I think we want a major merge to be
	  something on the order of 100,000 docs
	  For the 8 core experiment each core will have about 250K docs
	  So lets use 1/10th of that or 25K docs
      -->
      <majorMergeDocs>25000</majorMergeDocs>
      <bool name="mergeDetails">true</bool>
    </metrics>
  </indexConfig>

 
  <jmx />

  <!-- The default high-performance update handler -->
  <updateHandler class="solr.DirectUpdateHandler2">

     <!-- updateLogs keep entire solr documents.  Even if we purge it , that is way too much extra space and I/O
    our update process handles errors by keeping track of what ids get successfully indexed so we don't need this -->

<!--    <updateLog>
      <str name="dir">${solr.ulog.dir:}</str>
      <int name="numVersionBuckets">${solr.ulog.numVersionBuckets:65536}</int>
    </updateLog>
-->

    <!-- AutoCommit

         Perform a hard commit automatically under certain conditions.
         Instead of enabling autoCommit, consider using "commitWithin"
         when adding documents. 

         http://wiki.apache.org/solr/UpdateXmlMessages

         maxDocs - Maximum number of documents to add since the last
                   commit before automatically triggering a new commit.

         maxTime - Maximum amount of time in ms that is allowed to pass
                   since a document was added before automatically
                   triggering a new commit. 
         openSearcher - if false, the commit causes recent index changes
           to be flushed to stable storage, but does not cause a new
           searcher to be opened to make those changes visible.

         If the updateLog is enabled, then it's highly recommended to
         have some sort of hard autoCommit to limit the log size.
    -->
    
<!-- check whether some basic autocommit would be useful, i.e. when indexing 100,000 docs -->
<!-- apparently the unit is milliseconds so if we want an hour it would be 3,600,000 
     below we have it configured for every 10 hours
-->

     <autoCommit> 
       
       <maxTime>${solr.autoCommit.maxTime:36000000}</maxTime> 
       <openSearcher>false</openSearcher> 
     </autoCommit>

 <!-- We have no reason to do soft commits since the search server uses a static read-only index-->

   
  </updateHandler>
  
  

  <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       Query section - these settings control query time things like caches
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
  <query>
    <!-- Max Boolean Clauses

         Maximum number of clauses in each BooleanQuery,  an exception
         is thrown if exceeded.

         ** WARNING **
         
         This option actually modifies a global Lucene property that
         will affect all SolrCores.  If multiple solrconfig.xml files
         disagree on this property, the value at any given moment will
         be based on the last SolrCore to be initialized.
         
      -->
    <maxBooleanClauses>2048</maxBooleanClauses>

 
    <!-- Slow Query Threshold (in millis)
    
         At high request rates, logging all requests can become a bottleneck 
         and therefore INFO logging is often turned off. However, it is still
         useful to be able to set a latency threshold above which a request
         is considered "slow" and log that request at WARN level so we can
         easily identify slow queries.
    -->
    <!-- tbw set this to 10 seconds -->
    <slowQueryThresholdMillis>-10000</slowQueryThresholdMillis>


    <!-- Solr Internal Query Caches

         There are two implementations of cache available for Solr,
         LRUCache, based on a synchronized LinkedHashMap, and
         FastLRUCache, based on a ConcurrentHashMap.  

         FastLRUCache has faster gets and slower puts in single
         threaded operation and thus is generally faster than LRUCache
         when the hit ratio of the cache is high (> 75%), and may be
         faster under other scenarios on multi-cpu systems.
    -->

    <!--XXX tbw 2017  revisit these values and/or test
	consider replacing the size/initialzize with maxRamMB after benchmarking
    -->

    <filterCache class="solr.FastLRUCache"
                 size="512"
                 initialSize="512"
                 autowarmCount="128"/>

   
    <queryResultCache class="solr.LRUCache"
                     size="100000"
                     initialSize="100000"
                     autowarmCount="50000"/>
   
    <documentCache class="solr.LRUCache"
                   size="50000"
                   initialSize="50000"
                   autowarmCount="0"/>
    
    <!-- custom cache currently used by block join --> 
    <cache name="perSegFilter"
      class="solr.search.LRUCache"
      size="10"
      initialSize="0"
      autowarmCount="10"
      regenerator="solr.NoOpRegenerator" />

    <!-- Field Value Cache
         
         Cache used to hold field values that are quickly accessible
         by document id.  The fieldValueCache is created by default
         even if not configured here.
      -->
    <!--
       <fieldValueCache class="solr.FastLRUCache"
                        size="512"
                        autowarmCount="128"
                        showItems="32" />
      -->

    <!-- Feature Values Cache

         Cache used by the Learning To Rank (LTR) contrib module.

         You will need to set the solr.ltr.enabled system property
         when running solr to run with ltr enabled:
           -Dsolr.ltr.enabled=true

         https://cwiki.apache.org/confluence/display/solr/Learning+To+Rank
      -->
    <cache enable="${solr.ltr.enabled:false}" name="QUERY_DOC_FV"
           class="solr.search.LRUCache"
           size="4096"
           initialSize="2048"
           autowarmCount="4096"
           regenerator="solr.search.NoOpRegenerator" />


    <enableLazyFieldLoading>true</enableLazyFieldLoading>


   <!-- Result Window Size

        An optimization for use with the queryResultCache.  When a search
        is requested, a superset of the requested number of document ids
        are collected.  For example, if a search for a particular query
        requests matching documents 10 through 19, and queryWindowSize is 50,
        then documents 0 through 49 will be collected and cached.  Any further
        requests in that range can be satisfied via the cache.  
     -->
   <queryResultWindowSize>200</queryResultWindowSize>

   <!-- Maximum number of documents to cache for any entry in the
        queryResultCache. 
     -->
   <queryResultMaxDocsCached>200</queryResultMaxDocsCached>


    <useColdSearcher>false</useColdSearcher>
    <!-- tbw what happened to maxWarmingSearchers
	 this is from 4.10.2 config
	  <maxWarmingSearchers>2</maxWarmingSearchers>
    -->
  </query>


  <!-- Request Dispatcher

       This section contains instructions for how the SolrDispatchFilter
       should behave when processing requests for this SolrCore.

       handleSelect is a legacy option that affects the behavior of requests
       such as /select?qt=XXX

       handleSelect="true" will cause the SolrDispatchFilter to process
       the request and dispatch the query to a handler specified by the 
       "qt" param, assuming "/select" isn't already registered.

       handleSelect="false" will cause the SolrDispatchFilter to
       ignore "/select" requests, resulting in a 404 unless a handler
       is explicitly registered with the name "/select"

       handleSelect="true" is not recommended for new users, but is the default
       for backwards compatibility
  -->
  <!--XXX tbw time to review using this old setting and maybe change queries we send to solr-->
  <requestDispatcher handleSelect="true" >

    <!-- XXX tbw review this.  Don't think we want it and its a security issue -->
    <requestParsers enableRemoteStreaming="false" 
                    multipartUploadLimitInKB="2048000"
                    formdataUploadLimitInKB="2048"
                    addHttpRequestToContext="false"/>

    <httpCaching never304="true" />
  </requestDispatcher>

  
  <requestHandler name="/select" class="solr.SearchHandler">
    <!-- default values for query parameters can be specified, these
         will be overridden by parameters in the request
      -->
     <lst name="defaults">
       <str name="echoParams">explicit</str>
       <int name="rows">10</int>
       <!--XXX tbw WTF????  Research this to make sure its not doing something crazy-->
       <bool name="preferLocalShards">false</bool>
       <str name="df">ocr</str> <!-- i think this is illegal solr 6 tbw XXX-->
       <str name="indent">true</str>
     </lst>
    </requestHandler>

  <!-- A request handler that returns indented JSON by default -->
  <requestHandler name="/query" class="solr.SearchHandler">
     <lst name="defaults">
       <str name="echoParams">explicit</str>
       <str name="wt">json</str>
       <str name="indent">true</str>
       <str name="ocr">text</str>
     </lst>
  </requestHandler>

  

  <initParams path="/update/**,/query,/select,/tvrh,/elevate,/spell,/browse,update">
    <lst name="defaults">
      <str name="df">text</str>
    </lst>
  </initParams>

  <!-- The following are implicitly added
  <requestHandler name="/update/json" class="solr.UpdateRequestHandler">
        <lst name="invariants">
         <str name="stream.contentType">application/json</str>
       </lst>
  </requestHandler>
  <requestHandler name="/update/csv" class="solr.UpdateRequestHandler">
        <lst name="invariants">
         <str name="stream.contentType">application/csv</str>
       </lst>
  </requestHandler>
  -->

  <!-- Solr Cell Update Request Handler

       http://wiki.apache.org/solr/ExtractingRequestHandler 

    -->
  <requestHandler name="/update/extract" 
                  startup="lazy"
                  class="solr.extraction.ExtractingRequestHandler" >
    <lst name="defaults">
      <str name="lowernames">true</str>
      <str name="uprefix">ignored_</str>

      <!-- capture link hrefs but ignore div attributes -->
      <str name="captureAttr">true</str>
      <str name="fmap.a">links</str>
      <str name="fmap.div">ignored_</str>
    </lst>
  </requestHandler>
  <!--  tbw we have analysis/field, analysis/document, admin, pint, debug/dump handlers defined in 4.10.2.  now defined externally and configured with web api  See manual -->

  <!-- Term Vector Component

       http://wiki.apache.org/solr/TermVectorComponent
    -->
  <searchComponent name="tvComponent" class="solr.TermVectorComponent"/>

  <!-- A request handler for demonstrating the term vector component

       This is purely as an example.

       In reality you will likely want to add the component to your 
       already specified request handlers. 
    -->
  <requestHandler name="/tvrh" class="solr.SearchHandler" startup="lazy">
    <lst name="defaults">
      <bool name="tv">true</bool>
    </lst>
    <arr name="last-components">
      <str>tvComponent</str>
    </arr>
  </requestHandler>


  <!-- Terms Component

       http://wiki.apache.org/solr/TermsComponent

       A component to return terms and document frequency of those
       terms
    -->
  <searchComponent name="terms" class="solr.TermsComponent"/>

  <!-- A request handler for demonstrating the terms component -->
  <requestHandler name="/terms" class="solr.SearchHandler" startup="lazy">
     <lst name="defaults">
      <bool name="terms">true</bool>
      <bool name="distrib">false</bool>
    </lst>     
    <arr name="components">
      <str>terms</str>
    </arr>
  </requestHandler>

  
  <queryResponseWriter name="json" class="solr.JSONResponseWriter">
     <!-- For the purposes of the tutorial, JSON responses are written as
      plain text so that they are easy to read in *any* browser.
      If you expect a MIME type of "application/json" just remove this override.
     -->
    <str name="content-type">text/plain; charset=UTF-8</str>
  </queryResponseWriter>
  

  <queryParser enable="${solr.ltr.enabled:false}" name="ltr" class="org.apache.solr.ltr.search.LTRQParserPlugin"/>


    <!--
      LTR Transformer will encode the document features in the response. For each document the transformer
      will add the features as an extra field in the response. The name of the field will be the
      name of the transformer enclosed between brackets (in this case [features]).
      In order to get the feature vector you will have to specify that you
      want the field (e.g., fl="*,[features])

      You will need to set the solr.ltr.enabled system property
      when running solr to run with ltr enabled:
        -Dsolr.ltr.enabled=true

      https://cwiki.apache.org/confluence/display/solr/Learning+To+Rank
      -->
    <transformer enable="${solr.ltr.enabled:false}" name="features" class="org.apache.solr.ltr.response.transform.LTRFeatureLoggerTransformerFactory">
      <str name="fvCacheName">QUERY_DOC_FV</str>
    </transformer>

</config>
